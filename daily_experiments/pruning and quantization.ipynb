{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning and Quantization\n",
    "pruning and quantization could be applied on pretrained models, that is why I am thinking to use them as compression techniques other than other approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummaryX import summary\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================\n",
      "          Kernel Shape     Output Shape   Params Mult-Adds\n",
      "Layer                                                     \n",
      "0_conv1   [3, 6, 5, 5]   [1, 6, 28, 28]    456.0    352.8k\n",
      "1_pool               -   [1, 6, 14, 14]        -         -\n",
      "2_conv2  [6, 16, 5, 5]  [1, 16, 10, 10]   2.416k    240.0k\n",
      "3_pool               -    [1, 16, 5, 5]        -         -\n",
      "4_fc1       [400, 120]         [1, 120]   48.12k     48.0k\n",
      "5_fc2        [120, 84]          [1, 84]  10.164k    10.08k\n",
      "6_fc3         [84, 10]          [1, 10]    850.0     840.0\n",
      "-----------------------------------------------------------\n",
      "                       Totals\n",
      "Total params          62.006k\n",
      "Trainable params      62.006k\n",
      "Non-trainable params      0.0\n",
      "Mult-Adds             651.72k\n",
      "===========================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kernel Shape</th>\n",
       "      <th>Output Shape</th>\n",
       "      <th>Params</th>\n",
       "      <th>Mult-Adds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_conv1</th>\n",
       "      <td>[3, 6, 5, 5]</td>\n",
       "      <td>[1, 6, 28, 28]</td>\n",
       "      <td>456.0</td>\n",
       "      <td>352800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_pool</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 6, 14, 14]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_conv2</th>\n",
       "      <td>[6, 16, 5, 5]</td>\n",
       "      <td>[1, 16, 10, 10]</td>\n",
       "      <td>2416.0</td>\n",
       "      <td>240000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_pool</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 16, 5, 5]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_fc1</th>\n",
       "      <td>[400, 120]</td>\n",
       "      <td>[1, 120]</td>\n",
       "      <td>48120.0</td>\n",
       "      <td>48000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5_fc2</th>\n",
       "      <td>[120, 84]</td>\n",
       "      <td>[1, 84]</td>\n",
       "      <td>10164.0</td>\n",
       "      <td>10080.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_fc3</th>\n",
       "      <td>[84, 10]</td>\n",
       "      <td>[1, 10]</td>\n",
       "      <td>850.0</td>\n",
       "      <td>840.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Kernel Shape     Output Shape   Params  Mult-Adds\n",
       "Layer                                                      \n",
       "0_conv1   [3, 6, 5, 5]   [1, 6, 28, 28]    456.0   352800.0\n",
       "1_pool               -   [1, 6, 14, 14]      NaN        NaN\n",
       "2_conv2  [6, 16, 5, 5]  [1, 16, 10, 10]   2416.0   240000.0\n",
       "3_pool               -    [1, 16, 5, 5]      NaN        NaN\n",
       "4_fc1       [400, 120]         [1, 120]  48120.0    48000.0\n",
       "5_fc2        [120, 84]          [1, 84]  10164.0    10080.0\n",
       "6_fc3         [84, 10]          [1, 10]    850.0      840.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(net,torch.zeros([1, 3, 32, 32]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth\" to /home/aimsp/.cache/torch/checkpoints/resnext50_32x4d-7cdf4587.pth\n",
      "100%|██████████| 95.8M/95.8M [00:11<00:00, 8.49MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "model = models.resnext50_32x4d(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "                                             Kernel Shape       Output Shape  \\\n",
      "Layer                                                                          \n",
      "0_conv1                                     [3, 64, 7, 7]  [1, 64, 112, 112]   \n",
      "1_bn1                                                [64]  [1, 64, 112, 112]   \n",
      "2_relu                                                  -  [1, 64, 112, 112]   \n",
      "3_maxpool                                               -    [1, 64, 56, 56]   \n",
      "4_layer1.0.Conv2d_conv1                   [64, 128, 1, 1]   [1, 128, 56, 56]   \n",
      "5_layer1.0.BatchNorm2d_bn1                          [128]   [1, 128, 56, 56]   \n",
      "6_layer1.0.ReLU_relu                                    -   [1, 128, 56, 56]   \n",
      "7_layer1.0.Conv2d_conv2                    [4, 128, 3, 3]   [1, 128, 56, 56]   \n",
      "8_layer1.0.BatchNorm2d_bn2                          [128]   [1, 128, 56, 56]   \n",
      "9_layer1.0.ReLU_relu                                    -   [1, 128, 56, 56]   \n",
      "10_layer1.0.Conv2d_conv3                 [128, 256, 1, 1]   [1, 256, 56, 56]   \n",
      "11_layer1.0.BatchNorm2d_bn3                         [256]   [1, 256, 56, 56]   \n",
      "12_layer1.0.downsample.Conv2d_0           [64, 256, 1, 1]   [1, 256, 56, 56]   \n",
      "13_layer1.0.downsample.BatchNorm2d_1                [256]   [1, 256, 56, 56]   \n",
      "14_layer1.0.ReLU_relu                                   -   [1, 256, 56, 56]   \n",
      "15_layer1.1.Conv2d_conv1                 [256, 128, 1, 1]   [1, 128, 56, 56]   \n",
      "16_layer1.1.BatchNorm2d_bn1                         [128]   [1, 128, 56, 56]   \n",
      "17_layer1.1.ReLU_relu                                   -   [1, 128, 56, 56]   \n",
      "18_layer1.1.Conv2d_conv2                   [4, 128, 3, 3]   [1, 128, 56, 56]   \n",
      "19_layer1.1.BatchNorm2d_bn2                         [128]   [1, 128, 56, 56]   \n",
      "20_layer1.1.ReLU_relu                                   -   [1, 128, 56, 56]   \n",
      "21_layer1.1.Conv2d_conv3                 [128, 256, 1, 1]   [1, 256, 56, 56]   \n",
      "22_layer1.1.BatchNorm2d_bn3                         [256]   [1, 256, 56, 56]   \n",
      "23_layer1.1.ReLU_relu                                   -   [1, 256, 56, 56]   \n",
      "24_layer1.2.Conv2d_conv1                 [256, 128, 1, 1]   [1, 128, 56, 56]   \n",
      "25_layer1.2.BatchNorm2d_bn1                         [128]   [1, 128, 56, 56]   \n",
      "26_layer1.2.ReLU_relu                                   -   [1, 128, 56, 56]   \n",
      "27_layer1.2.Conv2d_conv2                   [4, 128, 3, 3]   [1, 128, 56, 56]   \n",
      "28_layer1.2.BatchNorm2d_bn2                         [128]   [1, 128, 56, 56]   \n",
      "29_layer1.2.ReLU_relu                                   -   [1, 128, 56, 56]   \n",
      "30_layer1.2.Conv2d_conv3                 [128, 256, 1, 1]   [1, 256, 56, 56]   \n",
      "31_layer1.2.BatchNorm2d_bn3                         [256]   [1, 256, 56, 56]   \n",
      "32_layer1.2.ReLU_relu                                   -   [1, 256, 56, 56]   \n",
      "33_layer2.0.Conv2d_conv1                 [256, 256, 1, 1]   [1, 256, 56, 56]   \n",
      "34_layer2.0.BatchNorm2d_bn1                         [256]   [1, 256, 56, 56]   \n",
      "35_layer2.0.ReLU_relu                                   -   [1, 256, 56, 56]   \n",
      "36_layer2.0.Conv2d_conv2                   [8, 256, 3, 3]   [1, 256, 28, 28]   \n",
      "37_layer2.0.BatchNorm2d_bn2                         [256]   [1, 256, 28, 28]   \n",
      "38_layer2.0.ReLU_relu                                   -   [1, 256, 28, 28]   \n",
      "39_layer2.0.Conv2d_conv3                 [256, 512, 1, 1]   [1, 512, 28, 28]   \n",
      "40_layer2.0.BatchNorm2d_bn3                         [512]   [1, 512, 28, 28]   \n",
      "41_layer2.0.downsample.Conv2d_0          [256, 512, 1, 1]   [1, 512, 28, 28]   \n",
      "42_layer2.0.downsample.BatchNorm2d_1                [512]   [1, 512, 28, 28]   \n",
      "43_layer2.0.ReLU_relu                                   -   [1, 512, 28, 28]   \n",
      "44_layer2.1.Conv2d_conv1                 [512, 256, 1, 1]   [1, 256, 28, 28]   \n",
      "45_layer2.1.BatchNorm2d_bn1                         [256]   [1, 256, 28, 28]   \n",
      "46_layer2.1.ReLU_relu                                   -   [1, 256, 28, 28]   \n",
      "47_layer2.1.Conv2d_conv2                   [8, 256, 3, 3]   [1, 256, 28, 28]   \n",
      "48_layer2.1.BatchNorm2d_bn2                         [256]   [1, 256, 28, 28]   \n",
      "49_layer2.1.ReLU_relu                                   -   [1, 256, 28, 28]   \n",
      "50_layer2.1.Conv2d_conv3                 [256, 512, 1, 1]   [1, 512, 28, 28]   \n",
      "51_layer2.1.BatchNorm2d_bn3                         [512]   [1, 512, 28, 28]   \n",
      "52_layer2.1.ReLU_relu                                   -   [1, 512, 28, 28]   \n",
      "53_layer2.2.Conv2d_conv1                 [512, 256, 1, 1]   [1, 256, 28, 28]   \n",
      "54_layer2.2.BatchNorm2d_bn1                         [256]   [1, 256, 28, 28]   \n",
      "55_layer2.2.ReLU_relu                                   -   [1, 256, 28, 28]   \n",
      "56_layer2.2.Conv2d_conv2                   [8, 256, 3, 3]   [1, 256, 28, 28]   \n",
      "57_layer2.2.BatchNorm2d_bn2                         [256]   [1, 256, 28, 28]   \n",
      "58_layer2.2.ReLU_relu                                   -   [1, 256, 28, 28]   \n",
      "59_layer2.2.Conv2d_conv3                 [256, 512, 1, 1]   [1, 512, 28, 28]   \n",
      "60_layer2.2.BatchNorm2d_bn3                         [512]   [1, 512, 28, 28]   \n",
      "61_layer2.2.ReLU_relu                                   -   [1, 512, 28, 28]   \n",
      "62_layer2.3.Conv2d_conv1                 [512, 256, 1, 1]   [1, 256, 28, 28]   \n",
      "63_layer2.3.BatchNorm2d_bn1                         [256]   [1, 256, 28, 28]   \n",
      "64_layer2.3.ReLU_relu                                   -   [1, 256, 28, 28]   \n",
      "65_layer2.3.Conv2d_conv2                   [8, 256, 3, 3]   [1, 256, 28, 28]   \n",
      "66_layer2.3.BatchNorm2d_bn2                         [256]   [1, 256, 28, 28]   \n",
      "67_layer2.3.ReLU_relu                                   -   [1, 256, 28, 28]   \n",
      "68_layer2.3.Conv2d_conv3                 [256, 512, 1, 1]   [1, 512, 28, 28]   \n",
      "69_layer2.3.BatchNorm2d_bn3                         [512]   [1, 512, 28, 28]   \n",
      "70_layer2.3.ReLU_relu                                   -   [1, 512, 28, 28]   \n",
      "71_layer3.0.Conv2d_conv1                 [512, 512, 1, 1]   [1, 512, 28, 28]   \n",
      "72_layer3.0.BatchNorm2d_bn1                         [512]   [1, 512, 28, 28]   \n",
      "73_layer3.0.ReLU_relu                                   -   [1, 512, 28, 28]   \n",
      "74_layer3.0.Conv2d_conv2                  [16, 512, 3, 3]   [1, 512, 14, 14]   \n",
      "75_layer3.0.BatchNorm2d_bn2                         [512]   [1, 512, 14, 14]   \n",
      "76_layer3.0.ReLU_relu                                   -   [1, 512, 14, 14]   \n",
      "77_layer3.0.Conv2d_conv3                [512, 1024, 1, 1]  [1, 1024, 14, 14]   \n",
      "78_layer3.0.BatchNorm2d_bn3                        [1024]  [1, 1024, 14, 14]   \n",
      "79_layer3.0.downsample.Conv2d_0         [512, 1024, 1, 1]  [1, 1024, 14, 14]   \n",
      "80_layer3.0.downsample.BatchNorm2d_1               [1024]  [1, 1024, 14, 14]   \n",
      "81_layer3.0.ReLU_relu                                   -  [1, 1024, 14, 14]   \n",
      "82_layer3.1.Conv2d_conv1                [1024, 512, 1, 1]   [1, 512, 14, 14]   \n",
      "83_layer3.1.BatchNorm2d_bn1                         [512]   [1, 512, 14, 14]   \n",
      "84_layer3.1.ReLU_relu                                   -   [1, 512, 14, 14]   \n",
      "85_layer3.1.Conv2d_conv2                  [16, 512, 3, 3]   [1, 512, 14, 14]   \n",
      "86_layer3.1.BatchNorm2d_bn2                         [512]   [1, 512, 14, 14]   \n",
      "87_layer3.1.ReLU_relu                                   -   [1, 512, 14, 14]   \n",
      "88_layer3.1.Conv2d_conv3                [512, 1024, 1, 1]  [1, 1024, 14, 14]   \n",
      "89_layer3.1.BatchNorm2d_bn3                        [1024]  [1, 1024, 14, 14]   \n",
      "90_layer3.1.ReLU_relu                                   -  [1, 1024, 14, 14]   \n",
      "91_layer3.2.Conv2d_conv1                [1024, 512, 1, 1]   [1, 512, 14, 14]   \n",
      "92_layer3.2.BatchNorm2d_bn1                         [512]   [1, 512, 14, 14]   \n",
      "93_layer3.2.ReLU_relu                                   -   [1, 512, 14, 14]   \n",
      "94_layer3.2.Conv2d_conv2                  [16, 512, 3, 3]   [1, 512, 14, 14]   \n",
      "95_layer3.2.BatchNorm2d_bn2                         [512]   [1, 512, 14, 14]   \n",
      "96_layer3.2.ReLU_relu                                   -   [1, 512, 14, 14]   \n",
      "97_layer3.2.Conv2d_conv3                [512, 1024, 1, 1]  [1, 1024, 14, 14]   \n",
      "98_layer3.2.BatchNorm2d_bn3                        [1024]  [1, 1024, 14, 14]   \n",
      "99_layer3.2.ReLU_relu                                   -  [1, 1024, 14, 14]   \n",
      "100_layer3.3.Conv2d_conv1               [1024, 512, 1, 1]   [1, 512, 14, 14]   \n",
      "101_layer3.3.BatchNorm2d_bn1                        [512]   [1, 512, 14, 14]   \n",
      "102_layer3.3.ReLU_relu                                  -   [1, 512, 14, 14]   \n",
      "103_layer3.3.Conv2d_conv2                 [16, 512, 3, 3]   [1, 512, 14, 14]   \n",
      "104_layer3.3.BatchNorm2d_bn2                        [512]   [1, 512, 14, 14]   \n",
      "105_layer3.3.ReLU_relu                                  -   [1, 512, 14, 14]   \n",
      "106_layer3.3.Conv2d_conv3               [512, 1024, 1, 1]  [1, 1024, 14, 14]   \n",
      "107_layer3.3.BatchNorm2d_bn3                       [1024]  [1, 1024, 14, 14]   \n",
      "108_layer3.3.ReLU_relu                                  -  [1, 1024, 14, 14]   \n",
      "109_layer3.4.Conv2d_conv1               [1024, 512, 1, 1]   [1, 512, 14, 14]   \n",
      "110_layer3.4.BatchNorm2d_bn1                        [512]   [1, 512, 14, 14]   \n",
      "111_layer3.4.ReLU_relu                                  -   [1, 512, 14, 14]   \n",
      "112_layer3.4.Conv2d_conv2                 [16, 512, 3, 3]   [1, 512, 14, 14]   \n",
      "113_layer3.4.BatchNorm2d_bn2                        [512]   [1, 512, 14, 14]   \n",
      "114_layer3.4.ReLU_relu                                  -   [1, 512, 14, 14]   \n",
      "115_layer3.4.Conv2d_conv3               [512, 1024, 1, 1]  [1, 1024, 14, 14]   \n",
      "116_layer3.4.BatchNorm2d_bn3                       [1024]  [1, 1024, 14, 14]   \n",
      "117_layer3.4.ReLU_relu                                  -  [1, 1024, 14, 14]   \n",
      "118_layer3.5.Conv2d_conv1               [1024, 512, 1, 1]   [1, 512, 14, 14]   \n",
      "119_layer3.5.BatchNorm2d_bn1                        [512]   [1, 512, 14, 14]   \n",
      "120_layer3.5.ReLU_relu                                  -   [1, 512, 14, 14]   \n",
      "121_layer3.5.Conv2d_conv2                 [16, 512, 3, 3]   [1, 512, 14, 14]   \n",
      "122_layer3.5.BatchNorm2d_bn2                        [512]   [1, 512, 14, 14]   \n",
      "123_layer3.5.ReLU_relu                                  -   [1, 512, 14, 14]   \n",
      "124_layer3.5.Conv2d_conv3               [512, 1024, 1, 1]  [1, 1024, 14, 14]   \n",
      "125_layer3.5.BatchNorm2d_bn3                       [1024]  [1, 1024, 14, 14]   \n",
      "126_layer3.5.ReLU_relu                                  -  [1, 1024, 14, 14]   \n",
      "127_layer4.0.Conv2d_conv1              [1024, 1024, 1, 1]  [1, 1024, 14, 14]   \n",
      "128_layer4.0.BatchNorm2d_bn1                       [1024]  [1, 1024, 14, 14]   \n",
      "129_layer4.0.ReLU_relu                                  -  [1, 1024, 14, 14]   \n",
      "130_layer4.0.Conv2d_conv2                [32, 1024, 3, 3]    [1, 1024, 7, 7]   \n",
      "131_layer4.0.BatchNorm2d_bn2                       [1024]    [1, 1024, 7, 7]   \n",
      "132_layer4.0.ReLU_relu                                  -    [1, 1024, 7, 7]   \n",
      "133_layer4.0.Conv2d_conv3              [1024, 2048, 1, 1]    [1, 2048, 7, 7]   \n",
      "134_layer4.0.BatchNorm2d_bn3                       [2048]    [1, 2048, 7, 7]   \n",
      "135_layer4.0.downsample.Conv2d_0       [1024, 2048, 1, 1]    [1, 2048, 7, 7]   \n",
      "136_layer4.0.downsample.BatchNorm2d_1              [2048]    [1, 2048, 7, 7]   \n",
      "137_layer4.0.ReLU_relu                                  -    [1, 2048, 7, 7]   \n",
      "138_layer4.1.Conv2d_conv1              [2048, 1024, 1, 1]    [1, 1024, 7, 7]   \n",
      "139_layer4.1.BatchNorm2d_bn1                       [1024]    [1, 1024, 7, 7]   \n",
      "140_layer4.1.ReLU_relu                                  -    [1, 1024, 7, 7]   \n",
      "141_layer4.1.Conv2d_conv2                [32, 1024, 3, 3]    [1, 1024, 7, 7]   \n",
      "142_layer4.1.BatchNorm2d_bn2                       [1024]    [1, 1024, 7, 7]   \n",
      "143_layer4.1.ReLU_relu                                  -    [1, 1024, 7, 7]   \n",
      "144_layer4.1.Conv2d_conv3              [1024, 2048, 1, 1]    [1, 2048, 7, 7]   \n",
      "145_layer4.1.BatchNorm2d_bn3                       [2048]    [1, 2048, 7, 7]   \n",
      "146_layer4.1.ReLU_relu                                  -    [1, 2048, 7, 7]   \n",
      "147_layer4.2.Conv2d_conv1              [2048, 1024, 1, 1]    [1, 1024, 7, 7]   \n",
      "148_layer4.2.BatchNorm2d_bn1                       [1024]    [1, 1024, 7, 7]   \n",
      "149_layer4.2.ReLU_relu                                  -    [1, 1024, 7, 7]   \n",
      "150_layer4.2.Conv2d_conv2                [32, 1024, 3, 3]    [1, 1024, 7, 7]   \n",
      "151_layer4.2.BatchNorm2d_bn2                       [1024]    [1, 1024, 7, 7]   \n",
      "152_layer4.2.ReLU_relu                                  -    [1, 1024, 7, 7]   \n",
      "153_layer4.2.Conv2d_conv3              [1024, 2048, 1, 1]    [1, 2048, 7, 7]   \n",
      "154_layer4.2.BatchNorm2d_bn3                       [2048]    [1, 2048, 7, 7]   \n",
      "155_layer4.2.ReLU_relu                                  -    [1, 2048, 7, 7]   \n",
      "156_avgpool                                             -    [1, 2048, 1, 1]   \n",
      "157_fc                                       [2048, 1000]          [1, 1000]   \n",
      "\n",
      "                                          Params    Mult-Adds  \n",
      "Layer                                                          \n",
      "0_conv1                                   9.408k  118.013952M  \n",
      "1_bn1                                      128.0         64.0  \n",
      "2_relu                                         -            -  \n",
      "3_maxpool                                      -            -  \n",
      "4_layer1.0.Conv2d_conv1                   8.192k   25.690112M  \n",
      "5_layer1.0.BatchNorm2d_bn1                 256.0        128.0  \n",
      "6_layer1.0.ReLU_relu                           -            -  \n",
      "7_layer1.0.Conv2d_conv2                   4.608k   14.450688M  \n",
      "8_layer1.0.BatchNorm2d_bn2                 256.0        128.0  \n",
      "9_layer1.0.ReLU_relu                           -            -  \n",
      "10_layer1.0.Conv2d_conv3                 32.768k  102.760448M  \n",
      "11_layer1.0.BatchNorm2d_bn3                512.0        256.0  \n",
      "12_layer1.0.downsample.Conv2d_0          16.384k   51.380224M  \n",
      "13_layer1.0.downsample.BatchNorm2d_1       512.0        256.0  \n",
      "14_layer1.0.ReLU_relu                          -            -  \n",
      "15_layer1.1.Conv2d_conv1                 32.768k  102.760448M  \n",
      "16_layer1.1.BatchNorm2d_bn1                256.0        128.0  \n",
      "17_layer1.1.ReLU_relu                          -            -  \n",
      "18_layer1.1.Conv2d_conv2                  4.608k   14.450688M  \n",
      "19_layer1.1.BatchNorm2d_bn2                256.0        128.0  \n",
      "20_layer1.1.ReLU_relu                          -            -  \n",
      "21_layer1.1.Conv2d_conv3                 32.768k  102.760448M  \n",
      "22_layer1.1.BatchNorm2d_bn3                512.0        256.0  \n",
      "23_layer1.1.ReLU_relu                          -            -  \n",
      "24_layer1.2.Conv2d_conv1                 32.768k  102.760448M  \n",
      "25_layer1.2.BatchNorm2d_bn1                256.0        128.0  \n",
      "26_layer1.2.ReLU_relu                          -            -  \n",
      "27_layer1.2.Conv2d_conv2                  4.608k   14.450688M  \n",
      "28_layer1.2.BatchNorm2d_bn2                256.0        128.0  \n",
      "29_layer1.2.ReLU_relu                          -            -  \n",
      "30_layer1.2.Conv2d_conv3                 32.768k  102.760448M  \n",
      "31_layer1.2.BatchNorm2d_bn3                512.0        256.0  \n",
      "32_layer1.2.ReLU_relu                          -            -  \n",
      "33_layer2.0.Conv2d_conv1                 65.536k  205.520896M  \n",
      "34_layer2.0.BatchNorm2d_bn1                512.0        256.0  \n",
      "35_layer2.0.ReLU_relu                          -            -  \n",
      "36_layer2.0.Conv2d_conv2                 18.432k   14.450688M  \n",
      "37_layer2.0.BatchNorm2d_bn2                512.0        256.0  \n",
      "38_layer2.0.ReLU_relu                          -            -  \n",
      "39_layer2.0.Conv2d_conv3                131.072k  102.760448M  \n",
      "40_layer2.0.BatchNorm2d_bn3               1.024k        512.0  \n",
      "41_layer2.0.downsample.Conv2d_0         131.072k  102.760448M  \n",
      "42_layer2.0.downsample.BatchNorm2d_1      1.024k        512.0  \n",
      "43_layer2.0.ReLU_relu                          -            -  \n",
      "44_layer2.1.Conv2d_conv1                131.072k  102.760448M  \n",
      "45_layer2.1.BatchNorm2d_bn1                512.0        256.0  \n",
      "46_layer2.1.ReLU_relu                          -            -  \n",
      "47_layer2.1.Conv2d_conv2                 18.432k   14.450688M  \n",
      "48_layer2.1.BatchNorm2d_bn2                512.0        256.0  \n",
      "49_layer2.1.ReLU_relu                          -            -  \n",
      "50_layer2.1.Conv2d_conv3                131.072k  102.760448M  \n",
      "51_layer2.1.BatchNorm2d_bn3               1.024k        512.0  \n",
      "52_layer2.1.ReLU_relu                          -            -  \n",
      "53_layer2.2.Conv2d_conv1                131.072k  102.760448M  \n",
      "54_layer2.2.BatchNorm2d_bn1                512.0        256.0  \n",
      "55_layer2.2.ReLU_relu                          -            -  \n",
      "56_layer2.2.Conv2d_conv2                 18.432k   14.450688M  \n",
      "57_layer2.2.BatchNorm2d_bn2                512.0        256.0  \n",
      "58_layer2.2.ReLU_relu                          -            -  \n",
      "59_layer2.2.Conv2d_conv3                131.072k  102.760448M  \n",
      "60_layer2.2.BatchNorm2d_bn3               1.024k        512.0  \n",
      "61_layer2.2.ReLU_relu                          -            -  \n",
      "62_layer2.3.Conv2d_conv1                131.072k  102.760448M  \n",
      "63_layer2.3.BatchNorm2d_bn1                512.0        256.0  \n",
      "64_layer2.3.ReLU_relu                          -            -  \n",
      "65_layer2.3.Conv2d_conv2                 18.432k   14.450688M  \n",
      "66_layer2.3.BatchNorm2d_bn2                512.0        256.0  \n",
      "67_layer2.3.ReLU_relu                          -            -  \n",
      "68_layer2.3.Conv2d_conv3                131.072k  102.760448M  \n",
      "69_layer2.3.BatchNorm2d_bn3               1.024k        512.0  \n",
      "70_layer2.3.ReLU_relu                          -            -  \n",
      "71_layer3.0.Conv2d_conv1                262.144k  205.520896M  \n",
      "72_layer3.0.BatchNorm2d_bn1               1.024k        512.0  \n",
      "73_layer3.0.ReLU_relu                          -            -  \n",
      "74_layer3.0.Conv2d_conv2                 73.728k   14.450688M  \n",
      "75_layer3.0.BatchNorm2d_bn2               1.024k        512.0  \n",
      "76_layer3.0.ReLU_relu                          -            -  \n",
      "77_layer3.0.Conv2d_conv3                524.288k  102.760448M  \n",
      "78_layer3.0.BatchNorm2d_bn3               2.048k       1.024k  \n",
      "79_layer3.0.downsample.Conv2d_0         524.288k  102.760448M  \n",
      "80_layer3.0.downsample.BatchNorm2d_1      2.048k       1.024k  \n",
      "81_layer3.0.ReLU_relu                          -            -  \n",
      "82_layer3.1.Conv2d_conv1                524.288k  102.760448M  \n",
      "83_layer3.1.BatchNorm2d_bn1               1.024k        512.0  \n",
      "84_layer3.1.ReLU_relu                          -            -  \n",
      "85_layer3.1.Conv2d_conv2                 73.728k   14.450688M  \n",
      "86_layer3.1.BatchNorm2d_bn2               1.024k        512.0  \n",
      "87_layer3.1.ReLU_relu                          -            -  \n",
      "88_layer3.1.Conv2d_conv3                524.288k  102.760448M  \n",
      "89_layer3.1.BatchNorm2d_bn3               2.048k       1.024k  \n",
      "90_layer3.1.ReLU_relu                          -            -  \n",
      "91_layer3.2.Conv2d_conv1                524.288k  102.760448M  \n",
      "92_layer3.2.BatchNorm2d_bn1               1.024k        512.0  \n",
      "93_layer3.2.ReLU_relu                          -            -  \n",
      "94_layer3.2.Conv2d_conv2                 73.728k   14.450688M  \n",
      "95_layer3.2.BatchNorm2d_bn2               1.024k        512.0  \n",
      "96_layer3.2.ReLU_relu                          -            -  \n",
      "97_layer3.2.Conv2d_conv3                524.288k  102.760448M  \n",
      "98_layer3.2.BatchNorm2d_bn3               2.048k       1.024k  \n",
      "99_layer3.2.ReLU_relu                          -            -  \n",
      "100_layer3.3.Conv2d_conv1               524.288k  102.760448M  \n",
      "101_layer3.3.BatchNorm2d_bn1              1.024k        512.0  \n",
      "102_layer3.3.ReLU_relu                         -            -  \n",
      "103_layer3.3.Conv2d_conv2                73.728k   14.450688M  \n",
      "104_layer3.3.BatchNorm2d_bn2              1.024k        512.0  \n",
      "105_layer3.3.ReLU_relu                         -            -  \n",
      "106_layer3.3.Conv2d_conv3               524.288k  102.760448M  \n",
      "107_layer3.3.BatchNorm2d_bn3              2.048k       1.024k  \n",
      "108_layer3.3.ReLU_relu                         -            -  \n",
      "109_layer3.4.Conv2d_conv1               524.288k  102.760448M  \n",
      "110_layer3.4.BatchNorm2d_bn1              1.024k        512.0  \n",
      "111_layer3.4.ReLU_relu                         -            -  \n",
      "112_layer3.4.Conv2d_conv2                73.728k   14.450688M  \n",
      "113_layer3.4.BatchNorm2d_bn2              1.024k        512.0  \n",
      "114_layer3.4.ReLU_relu                         -            -  \n",
      "115_layer3.4.Conv2d_conv3               524.288k  102.760448M  \n",
      "116_layer3.4.BatchNorm2d_bn3              2.048k       1.024k  \n",
      "117_layer3.4.ReLU_relu                         -            -  \n",
      "118_layer3.5.Conv2d_conv1               524.288k  102.760448M  \n",
      "119_layer3.5.BatchNorm2d_bn1              1.024k        512.0  \n",
      "120_layer3.5.ReLU_relu                         -            -  \n",
      "121_layer3.5.Conv2d_conv2                73.728k   14.450688M  \n",
      "122_layer3.5.BatchNorm2d_bn2              1.024k        512.0  \n",
      "123_layer3.5.ReLU_relu                         -            -  \n",
      "124_layer3.5.Conv2d_conv3               524.288k  102.760448M  \n",
      "125_layer3.5.BatchNorm2d_bn3              2.048k       1.024k  \n",
      "126_layer3.5.ReLU_relu                         -            -  \n",
      "127_layer4.0.Conv2d_conv1              1.048576M  205.520896M  \n",
      "128_layer4.0.BatchNorm2d_bn1              2.048k       1.024k  \n",
      "129_layer4.0.ReLU_relu                         -            -  \n",
      "130_layer4.0.Conv2d_conv2               294.912k   14.450688M  \n",
      "131_layer4.0.BatchNorm2d_bn2              2.048k       1.024k  \n",
      "132_layer4.0.ReLU_relu                         -            -  \n",
      "133_layer4.0.Conv2d_conv3              2.097152M  102.760448M  \n",
      "134_layer4.0.BatchNorm2d_bn3              4.096k       2.048k  \n",
      "135_layer4.0.downsample.Conv2d_0       2.097152M  102.760448M  \n",
      "136_layer4.0.downsample.BatchNorm2d_1     4.096k       2.048k  \n",
      "137_layer4.0.ReLU_relu                         -            -  \n",
      "138_layer4.1.Conv2d_conv1              2.097152M  102.760448M  \n",
      "139_layer4.1.BatchNorm2d_bn1              2.048k       1.024k  \n",
      "140_layer4.1.ReLU_relu                         -            -  \n",
      "141_layer4.1.Conv2d_conv2               294.912k   14.450688M  \n",
      "142_layer4.1.BatchNorm2d_bn2              2.048k       1.024k  \n",
      "143_layer4.1.ReLU_relu                         -            -  \n",
      "144_layer4.1.Conv2d_conv3              2.097152M  102.760448M  \n",
      "145_layer4.1.BatchNorm2d_bn3              4.096k       2.048k  \n",
      "146_layer4.1.ReLU_relu                         -            -  \n",
      "147_layer4.2.Conv2d_conv1              2.097152M  102.760448M  \n",
      "148_layer4.2.BatchNorm2d_bn1              2.048k       1.024k  \n",
      "149_layer4.2.ReLU_relu                         -            -  \n",
      "150_layer4.2.Conv2d_conv2               294.912k   14.450688M  \n",
      "151_layer4.2.BatchNorm2d_bn2              2.048k       1.024k  \n",
      "152_layer4.2.ReLU_relu                         -            -  \n",
      "153_layer4.2.Conv2d_conv3              2.097152M  102.760448M  \n",
      "154_layer4.2.BatchNorm2d_bn3              4.096k       2.048k  \n",
      "155_layer4.2.ReLU_relu                         -            -  \n",
      "156_avgpool                                    -            -  \n",
      "157_fc                                    2.049M       2.048M  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "                            Totals\n",
      "Total params            25.028904M\n",
      "Trainable params        25.028904M\n",
      "Non-trainable params           0.0\n",
      "Mult-Adds             4.230513984G\n",
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kernel Shape</th>\n",
       "      <th>Output Shape</th>\n",
       "      <th>Params</th>\n",
       "      <th>Mult-Adds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_conv1</th>\n",
       "      <td>[3, 64, 7, 7]</td>\n",
       "      <td>[1, 64, 112, 112]</td>\n",
       "      <td>9408.0</td>\n",
       "      <td>118013952.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_bn1</th>\n",
       "      <td>[64]</td>\n",
       "      <td>[1, 64, 112, 112]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 64, 112, 112]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_maxpool</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 64, 56, 56]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_layer1.0.Conv2d_conv1</th>\n",
       "      <td>[64, 128, 1, 1]</td>\n",
       "      <td>[1, 128, 56, 56]</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>25690112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5_layer1.0.BatchNorm2d_bn1</th>\n",
       "      <td>[128]</td>\n",
       "      <td>[1, 128, 56, 56]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_layer1.0.ReLU_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 128, 56, 56]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7_layer1.0.Conv2d_conv2</th>\n",
       "      <td>[4, 128, 3, 3]</td>\n",
       "      <td>[1, 128, 56, 56]</td>\n",
       "      <td>4608.0</td>\n",
       "      <td>14450688.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8_layer1.0.BatchNorm2d_bn2</th>\n",
       "      <td>[128]</td>\n",
       "      <td>[1, 128, 56, 56]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9_layer1.0.ReLU_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 128, 56, 56]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10_layer1.0.Conv2d_conv3</th>\n",
       "      <td>[128, 256, 1, 1]</td>\n",
       "      <td>[1, 256, 56, 56]</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>102760448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11_layer1.0.BatchNorm2d_bn3</th>\n",
       "      <td>[256]</td>\n",
       "      <td>[1, 256, 56, 56]</td>\n",
       "      <td>512.0</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12_layer1.0.downsample.Conv2d_0</th>\n",
       "      <td>[64, 256, 1, 1]</td>\n",
       "      <td>[1, 256, 56, 56]</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>51380224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13_layer1.0.downsample.BatchNorm2d_1</th>\n",
       "      <td>[256]</td>\n",
       "      <td>[1, 256, 56, 56]</td>\n",
       "      <td>512.0</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14_layer1.0.ReLU_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 256, 56, 56]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15_layer1.1.Conv2d_conv1</th>\n",
       "      <td>[256, 128, 1, 1]</td>\n",
       "      <td>[1, 128, 56, 56]</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>102760448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16_layer1.1.BatchNorm2d_bn1</th>\n",
       "      <td>[128]</td>\n",
       "      <td>[1, 128, 56, 56]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17_layer1.1.ReLU_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 128, 56, 56]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18_layer1.1.Conv2d_conv2</th>\n",
       "      <td>[4, 128, 3, 3]</td>\n",
       "      <td>[1, 128, 56, 56]</td>\n",
       "      <td>4608.0</td>\n",
       "      <td>14450688.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19_layer1.1.BatchNorm2d_bn2</th>\n",
       "      <td>[128]</td>\n",
       "      <td>[1, 128, 56, 56]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20_layer1.1.ReLU_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 128, 56, 56]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21_layer1.1.Conv2d_conv3</th>\n",
       "      <td>[128, 256, 1, 1]</td>\n",
       "      <td>[1, 256, 56, 56]</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>102760448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22_layer1.1.BatchNorm2d_bn3</th>\n",
       "      <td>[256]</td>\n",
       "      <td>[1, 256, 56, 56]</td>\n",
       "      <td>512.0</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23_layer1.1.ReLU_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 256, 56, 56]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24_layer1.2.Conv2d_conv1</th>\n",
       "      <td>[256, 128, 1, 1]</td>\n",
       "      <td>[1, 128, 56, 56]</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>102760448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25_layer1.2.BatchNorm2d_bn1</th>\n",
       "      <td>[128]</td>\n",
       "      <td>[1, 128, 56, 56]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26_layer1.2.ReLU_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 128, 56, 56]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27_layer1.2.Conv2d_conv2</th>\n",
       "      <td>[4, 128, 3, 3]</td>\n",
       "      <td>[1, 128, 56, 56]</td>\n",
       "      <td>4608.0</td>\n",
       "      <td>14450688.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28_layer1.2.BatchNorm2d_bn2</th>\n",
       "      <td>[128]</td>\n",
       "      <td>[1, 128, 56, 56]</td>\n",
       "      <td>256.0</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29_layer1.2.ReLU_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 128, 56, 56]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128_layer4.0.BatchNorm2d_bn1</th>\n",
       "      <td>[1024]</td>\n",
       "      <td>[1, 1024, 14, 14]</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>1024.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129_layer4.0.ReLU_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 1024, 14, 14]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130_layer4.0.Conv2d_conv2</th>\n",
       "      <td>[32, 1024, 3, 3]</td>\n",
       "      <td>[1, 1024, 7, 7]</td>\n",
       "      <td>294912.0</td>\n",
       "      <td>14450688.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131_layer4.0.BatchNorm2d_bn2</th>\n",
       "      <td>[1024]</td>\n",
       "      <td>[1, 1024, 7, 7]</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>1024.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132_layer4.0.ReLU_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 1024, 7, 7]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133_layer4.0.Conv2d_conv3</th>\n",
       "      <td>[1024, 2048, 1, 1]</td>\n",
       "      <td>[1, 2048, 7, 7]</td>\n",
       "      <td>2097152.0</td>\n",
       "      <td>102760448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134_layer4.0.BatchNorm2d_bn3</th>\n",
       "      <td>[2048]</td>\n",
       "      <td>[1, 2048, 7, 7]</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>2048.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135_layer4.0.downsample.Conv2d_0</th>\n",
       "      <td>[1024, 2048, 1, 1]</td>\n",
       "      <td>[1, 2048, 7, 7]</td>\n",
       "      <td>2097152.0</td>\n",
       "      <td>102760448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136_layer4.0.downsample.BatchNorm2d_1</th>\n",
       "      <td>[2048]</td>\n",
       "      <td>[1, 2048, 7, 7]</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>2048.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137_layer4.0.ReLU_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 2048, 7, 7]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138_layer4.1.Conv2d_conv1</th>\n",
       "      <td>[2048, 1024, 1, 1]</td>\n",
       "      <td>[1, 1024, 7, 7]</td>\n",
       "      <td>2097152.0</td>\n",
       "      <td>102760448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139_layer4.1.BatchNorm2d_bn1</th>\n",
       "      <td>[1024]</td>\n",
       "      <td>[1, 1024, 7, 7]</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>1024.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140_layer4.1.ReLU_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 1024, 7, 7]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141_layer4.1.Conv2d_conv2</th>\n",
       "      <td>[32, 1024, 3, 3]</td>\n",
       "      <td>[1, 1024, 7, 7]</td>\n",
       "      <td>294912.0</td>\n",
       "      <td>14450688.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142_layer4.1.BatchNorm2d_bn2</th>\n",
       "      <td>[1024]</td>\n",
       "      <td>[1, 1024, 7, 7]</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>1024.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143_layer4.1.ReLU_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 1024, 7, 7]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144_layer4.1.Conv2d_conv3</th>\n",
       "      <td>[1024, 2048, 1, 1]</td>\n",
       "      <td>[1, 2048, 7, 7]</td>\n",
       "      <td>2097152.0</td>\n",
       "      <td>102760448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145_layer4.1.BatchNorm2d_bn3</th>\n",
       "      <td>[2048]</td>\n",
       "      <td>[1, 2048, 7, 7]</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>2048.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146_layer4.1.ReLU_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 2048, 7, 7]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147_layer4.2.Conv2d_conv1</th>\n",
       "      <td>[2048, 1024, 1, 1]</td>\n",
       "      <td>[1, 1024, 7, 7]</td>\n",
       "      <td>2097152.0</td>\n",
       "      <td>102760448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148_layer4.2.BatchNorm2d_bn1</th>\n",
       "      <td>[1024]</td>\n",
       "      <td>[1, 1024, 7, 7]</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>1024.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149_layer4.2.ReLU_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 1024, 7, 7]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150_layer4.2.Conv2d_conv2</th>\n",
       "      <td>[32, 1024, 3, 3]</td>\n",
       "      <td>[1, 1024, 7, 7]</td>\n",
       "      <td>294912.0</td>\n",
       "      <td>14450688.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151_layer4.2.BatchNorm2d_bn2</th>\n",
       "      <td>[1024]</td>\n",
       "      <td>[1, 1024, 7, 7]</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>1024.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152_layer4.2.ReLU_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 1024, 7, 7]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153_layer4.2.Conv2d_conv3</th>\n",
       "      <td>[1024, 2048, 1, 1]</td>\n",
       "      <td>[1, 2048, 7, 7]</td>\n",
       "      <td>2097152.0</td>\n",
       "      <td>102760448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154_layer4.2.BatchNorm2d_bn3</th>\n",
       "      <td>[2048]</td>\n",
       "      <td>[1, 2048, 7, 7]</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>2048.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155_layer4.2.ReLU_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 2048, 7, 7]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156_avgpool</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 2048, 1, 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157_fc</th>\n",
       "      <td>[2048, 1000]</td>\n",
       "      <td>[1, 1000]</td>\n",
       "      <td>2049000.0</td>\n",
       "      <td>2048000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Kernel Shape       Output Shape  \\\n",
       "Layer                                                                          \n",
       "0_conv1                                     [3, 64, 7, 7]  [1, 64, 112, 112]   \n",
       "1_bn1                                                [64]  [1, 64, 112, 112]   \n",
       "2_relu                                                  -  [1, 64, 112, 112]   \n",
       "3_maxpool                                               -    [1, 64, 56, 56]   \n",
       "4_layer1.0.Conv2d_conv1                   [64, 128, 1, 1]   [1, 128, 56, 56]   \n",
       "5_layer1.0.BatchNorm2d_bn1                          [128]   [1, 128, 56, 56]   \n",
       "6_layer1.0.ReLU_relu                                    -   [1, 128, 56, 56]   \n",
       "7_layer1.0.Conv2d_conv2                    [4, 128, 3, 3]   [1, 128, 56, 56]   \n",
       "8_layer1.0.BatchNorm2d_bn2                          [128]   [1, 128, 56, 56]   \n",
       "9_layer1.0.ReLU_relu                                    -   [1, 128, 56, 56]   \n",
       "10_layer1.0.Conv2d_conv3                 [128, 256, 1, 1]   [1, 256, 56, 56]   \n",
       "11_layer1.0.BatchNorm2d_bn3                         [256]   [1, 256, 56, 56]   \n",
       "12_layer1.0.downsample.Conv2d_0           [64, 256, 1, 1]   [1, 256, 56, 56]   \n",
       "13_layer1.0.downsample.BatchNorm2d_1                [256]   [1, 256, 56, 56]   \n",
       "14_layer1.0.ReLU_relu                                   -   [1, 256, 56, 56]   \n",
       "15_layer1.1.Conv2d_conv1                 [256, 128, 1, 1]   [1, 128, 56, 56]   \n",
       "16_layer1.1.BatchNorm2d_bn1                         [128]   [1, 128, 56, 56]   \n",
       "17_layer1.1.ReLU_relu                                   -   [1, 128, 56, 56]   \n",
       "18_layer1.1.Conv2d_conv2                   [4, 128, 3, 3]   [1, 128, 56, 56]   \n",
       "19_layer1.1.BatchNorm2d_bn2                         [128]   [1, 128, 56, 56]   \n",
       "20_layer1.1.ReLU_relu                                   -   [1, 128, 56, 56]   \n",
       "21_layer1.1.Conv2d_conv3                 [128, 256, 1, 1]   [1, 256, 56, 56]   \n",
       "22_layer1.1.BatchNorm2d_bn3                         [256]   [1, 256, 56, 56]   \n",
       "23_layer1.1.ReLU_relu                                   -   [1, 256, 56, 56]   \n",
       "24_layer1.2.Conv2d_conv1                 [256, 128, 1, 1]   [1, 128, 56, 56]   \n",
       "25_layer1.2.BatchNorm2d_bn1                         [128]   [1, 128, 56, 56]   \n",
       "26_layer1.2.ReLU_relu                                   -   [1, 128, 56, 56]   \n",
       "27_layer1.2.Conv2d_conv2                   [4, 128, 3, 3]   [1, 128, 56, 56]   \n",
       "28_layer1.2.BatchNorm2d_bn2                         [128]   [1, 128, 56, 56]   \n",
       "29_layer1.2.ReLU_relu                                   -   [1, 128, 56, 56]   \n",
       "...                                                   ...                ...   \n",
       "128_layer4.0.BatchNorm2d_bn1                       [1024]  [1, 1024, 14, 14]   \n",
       "129_layer4.0.ReLU_relu                                  -  [1, 1024, 14, 14]   \n",
       "130_layer4.0.Conv2d_conv2                [32, 1024, 3, 3]    [1, 1024, 7, 7]   \n",
       "131_layer4.0.BatchNorm2d_bn2                       [1024]    [1, 1024, 7, 7]   \n",
       "132_layer4.0.ReLU_relu                                  -    [1, 1024, 7, 7]   \n",
       "133_layer4.0.Conv2d_conv3              [1024, 2048, 1, 1]    [1, 2048, 7, 7]   \n",
       "134_layer4.0.BatchNorm2d_bn3                       [2048]    [1, 2048, 7, 7]   \n",
       "135_layer4.0.downsample.Conv2d_0       [1024, 2048, 1, 1]    [1, 2048, 7, 7]   \n",
       "136_layer4.0.downsample.BatchNorm2d_1              [2048]    [1, 2048, 7, 7]   \n",
       "137_layer4.0.ReLU_relu                                  -    [1, 2048, 7, 7]   \n",
       "138_layer4.1.Conv2d_conv1              [2048, 1024, 1, 1]    [1, 1024, 7, 7]   \n",
       "139_layer4.1.BatchNorm2d_bn1                       [1024]    [1, 1024, 7, 7]   \n",
       "140_layer4.1.ReLU_relu                                  -    [1, 1024, 7, 7]   \n",
       "141_layer4.1.Conv2d_conv2                [32, 1024, 3, 3]    [1, 1024, 7, 7]   \n",
       "142_layer4.1.BatchNorm2d_bn2                       [1024]    [1, 1024, 7, 7]   \n",
       "143_layer4.1.ReLU_relu                                  -    [1, 1024, 7, 7]   \n",
       "144_layer4.1.Conv2d_conv3              [1024, 2048, 1, 1]    [1, 2048, 7, 7]   \n",
       "145_layer4.1.BatchNorm2d_bn3                       [2048]    [1, 2048, 7, 7]   \n",
       "146_layer4.1.ReLU_relu                                  -    [1, 2048, 7, 7]   \n",
       "147_layer4.2.Conv2d_conv1              [2048, 1024, 1, 1]    [1, 1024, 7, 7]   \n",
       "148_layer4.2.BatchNorm2d_bn1                       [1024]    [1, 1024, 7, 7]   \n",
       "149_layer4.2.ReLU_relu                                  -    [1, 1024, 7, 7]   \n",
       "150_layer4.2.Conv2d_conv2                [32, 1024, 3, 3]    [1, 1024, 7, 7]   \n",
       "151_layer4.2.BatchNorm2d_bn2                       [1024]    [1, 1024, 7, 7]   \n",
       "152_layer4.2.ReLU_relu                                  -    [1, 1024, 7, 7]   \n",
       "153_layer4.2.Conv2d_conv3              [1024, 2048, 1, 1]    [1, 2048, 7, 7]   \n",
       "154_layer4.2.BatchNorm2d_bn3                       [2048]    [1, 2048, 7, 7]   \n",
       "155_layer4.2.ReLU_relu                                  -    [1, 2048, 7, 7]   \n",
       "156_avgpool                                             -    [1, 2048, 1, 1]   \n",
       "157_fc                                       [2048, 1000]          [1, 1000]   \n",
       "\n",
       "                                          Params    Mult-Adds  \n",
       "Layer                                                          \n",
       "0_conv1                                   9408.0  118013952.0  \n",
       "1_bn1                                      128.0         64.0  \n",
       "2_relu                                       NaN          NaN  \n",
       "3_maxpool                                    NaN          NaN  \n",
       "4_layer1.0.Conv2d_conv1                   8192.0   25690112.0  \n",
       "5_layer1.0.BatchNorm2d_bn1                 256.0        128.0  \n",
       "6_layer1.0.ReLU_relu                         NaN          NaN  \n",
       "7_layer1.0.Conv2d_conv2                   4608.0   14450688.0  \n",
       "8_layer1.0.BatchNorm2d_bn2                 256.0        128.0  \n",
       "9_layer1.0.ReLU_relu                         NaN          NaN  \n",
       "10_layer1.0.Conv2d_conv3                 32768.0  102760448.0  \n",
       "11_layer1.0.BatchNorm2d_bn3                512.0        256.0  \n",
       "12_layer1.0.downsample.Conv2d_0          16384.0   51380224.0  \n",
       "13_layer1.0.downsample.BatchNorm2d_1       512.0        256.0  \n",
       "14_layer1.0.ReLU_relu                        NaN          NaN  \n",
       "15_layer1.1.Conv2d_conv1                 32768.0  102760448.0  \n",
       "16_layer1.1.BatchNorm2d_bn1                256.0        128.0  \n",
       "17_layer1.1.ReLU_relu                        NaN          NaN  \n",
       "18_layer1.1.Conv2d_conv2                  4608.0   14450688.0  \n",
       "19_layer1.1.BatchNorm2d_bn2                256.0        128.0  \n",
       "20_layer1.1.ReLU_relu                        NaN          NaN  \n",
       "21_layer1.1.Conv2d_conv3                 32768.0  102760448.0  \n",
       "22_layer1.1.BatchNorm2d_bn3                512.0        256.0  \n",
       "23_layer1.1.ReLU_relu                        NaN          NaN  \n",
       "24_layer1.2.Conv2d_conv1                 32768.0  102760448.0  \n",
       "25_layer1.2.BatchNorm2d_bn1                256.0        128.0  \n",
       "26_layer1.2.ReLU_relu                        NaN          NaN  \n",
       "27_layer1.2.Conv2d_conv2                  4608.0   14450688.0  \n",
       "28_layer1.2.BatchNorm2d_bn2                256.0        128.0  \n",
       "29_layer1.2.ReLU_relu                        NaN          NaN  \n",
       "...                                          ...          ...  \n",
       "128_layer4.0.BatchNorm2d_bn1              2048.0       1024.0  \n",
       "129_layer4.0.ReLU_relu                       NaN          NaN  \n",
       "130_layer4.0.Conv2d_conv2               294912.0   14450688.0  \n",
       "131_layer4.0.BatchNorm2d_bn2              2048.0       1024.0  \n",
       "132_layer4.0.ReLU_relu                       NaN          NaN  \n",
       "133_layer4.0.Conv2d_conv3              2097152.0  102760448.0  \n",
       "134_layer4.0.BatchNorm2d_bn3              4096.0       2048.0  \n",
       "135_layer4.0.downsample.Conv2d_0       2097152.0  102760448.0  \n",
       "136_layer4.0.downsample.BatchNorm2d_1     4096.0       2048.0  \n",
       "137_layer4.0.ReLU_relu                       NaN          NaN  \n",
       "138_layer4.1.Conv2d_conv1              2097152.0  102760448.0  \n",
       "139_layer4.1.BatchNorm2d_bn1              2048.0       1024.0  \n",
       "140_layer4.1.ReLU_relu                       NaN          NaN  \n",
       "141_layer4.1.Conv2d_conv2               294912.0   14450688.0  \n",
       "142_layer4.1.BatchNorm2d_bn2              2048.0       1024.0  \n",
       "143_layer4.1.ReLU_relu                       NaN          NaN  \n",
       "144_layer4.1.Conv2d_conv3              2097152.0  102760448.0  \n",
       "145_layer4.1.BatchNorm2d_bn3              4096.0       2048.0  \n",
       "146_layer4.1.ReLU_relu                       NaN          NaN  \n",
       "147_layer4.2.Conv2d_conv1              2097152.0  102760448.0  \n",
       "148_layer4.2.BatchNorm2d_bn1              2048.0       1024.0  \n",
       "149_layer4.2.ReLU_relu                       NaN          NaN  \n",
       "150_layer4.2.Conv2d_conv2               294912.0   14450688.0  \n",
       "151_layer4.2.BatchNorm2d_bn2              2048.0       1024.0  \n",
       "152_layer4.2.ReLU_relu                       NaN          NaN  \n",
       "153_layer4.2.Conv2d_conv3              2097152.0  102760448.0  \n",
       "154_layer4.2.BatchNorm2d_bn3              4096.0       2048.0  \n",
       "155_layer4.2.ReLU_relu                       NaN          NaN  \n",
       "156_avgpool                                  NaN          NaN  \n",
       "157_fc                                 2049000.0    2048000.0  \n",
       "\n",
       "[158 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model,torch.zeros([1, 3, 224, 224]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.1+cpu\n"
     ]
    }
   ],
   "source": [
    " print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch.nn.utils.prune'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-6d875b5ca12b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprune\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprune\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch.nn.utils.prune'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
