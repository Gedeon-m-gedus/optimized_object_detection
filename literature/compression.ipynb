{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL COMPRESSION\n",
    "\n",
    "**Motivation**: Design and implementation of object detection model that could run efficiently on edge devices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Challenges of Deep learning on edge devices\n",
    "+ Model size\n",
    "+ Inference speed (number of computations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Operation | Energy[pJ] | Relative cost |\n",
    "| --- | --- | --- |\n",
    "| 32bit int ADD | 0.1 | 1 |\n",
    "| 32bit float ADD | 0.9 | 9 |\n",
    "| 32bit register file | 1 | 10 |\n",
    "| 32bit int MULT | 3.1 | 31 |\n",
    "| 32bit float MULT | 3.7 | 37 |\n",
    "| 32bit SRAM Cash | 5 | 50 |\n",
    "| <font color=red>32bit DRAM Memory</font> | <font color=red>640</font> | <font color=red>6400</font> |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model compression pipeline\n",
    "The most problem of runnig deep models on edge devices is due to the memory size and the number of computations required at inference.\n",
    "\n",
    "\n",
    "+ **Pruning** would help to remove redundancy and sparsity in the model weights\n",
    "+ **Quantization** would help in storage as well as computation as the numbers will be represented by few bits\n",
    "+ I am suggesting to add **Tensor decomposition**: the idea is to compute the rank of the weight matrix and store it more efficiently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"tensor_decomposition2.jpg\"\n",
    "     alt=\"Markdown Monster icon\"\n",
    "     style=\"float: left; margin-right: 10px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor decomposition\n",
    "\n",
    "Tensor decomposition could help to do model compression.\n",
    "The idea behind is to compute the rank of the weight matrix and store the parameters more efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of matrix decomposition for reducing the number of parameters\n",
    "Assume $A = \\begin{bmatrix} 3 & 2 & 2 \\\\ 2 & 3 & -2 \\end{bmatrix}$\n",
    " is a rectangular matrix, $A \\in I\\!R^{2x3}$\n",
    " + if we assume this matrix to be our weight matrix, the total number of parameters will be <font color=red>$2 \\times 3 = 6$</font> \n",
    " + Using SVD A can be represented as $A=U \\Sigma V^T$\n",
    " \n",
    "The SVD of matrix $A$ will be: $A = \n",
    "\\begin{bmatrix} \\frac{1}{\\sqrt{2}} & \\frac{1}{\\sqrt{2}}  \\\\ \\frac{1}{\\sqrt{2}} & -\\frac{1}{\\sqrt{2}} \\end{bmatrix}\n",
    "\\begin{bmatrix} 5 & 0 & 0 \\\\ 0 & 3 & 0 \\end{bmatrix}\n",
    "\\begin{bmatrix} \\frac{1}{\\sqrt{2}} & \\frac{1}{\\sqrt{2}} & 0 \\\\ \\frac{1}{\\sqrt{18}} & -\\frac{1}{\\sqrt{18}} & \\frac{4}{\\sqrt{18}}\\\\ \\frac{2}{3} & -\\frac{2}{3} & -\\frac{1}{3} \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
